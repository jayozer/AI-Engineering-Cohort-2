{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.google.com/forms/d/e/1FAIpQLSfRHORtHFiPUGCiYNt2NfapWtgUQWbv5V75kUPwUAkx20r9Eg/viewform\n",
    "\n",
    "\"What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\"\n",
    "\n",
    "\"Who are Meta's 'Directors' (i.e., members of the Board of Directors)?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data (pdf)\n",
    "2. Process data - using llama parse (proprietary parsing w embedded object - tables and figures - exactly what i am looking for.) Build retrieval over complex and semi structured documents. - production grade context agumentation. (Suits well with my EOB parsing and loading project). Does it in markdown format - because easier to read the format and parse. Makes sense. Using recursive retriever.\n",
    "-- Check figure extraction\n",
    "\n",
    "Knowledge corpus - 1st Stage Embedding based retrival - docs - 2nd stage LLM based reranking - Docs.....\n",
    "Load vectors into Database Qrand\n",
    "1. Getting llmam parse to work. \n",
    "2. retrieval - query engines.\n",
    "\n",
    "\n",
    "llamaparse - nice tabular extraction - which I need for meta. Speed is lsow and figures are not retirieved correctlt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU llama-index llama-parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = getpass.getpass(\"LLamaParse API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you are in a Jupyter Notebook - I did.\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\", # set it to markdown so preservess sturcture\n",
    "    verbose=True,  # output detail logs\n",
    "    language=\"en\",\n",
    "    num_workers=1,  #I will parse one worker since I only parse one. \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a folder and then download and update its name:\n",
    "!mkdir -p 'data/'\n",
    "!wget 'https://d18rn0p25nwr6d.cloudfront.net/CIK-0001326801/c7318154-f6ae-4866-89fa-f0c589f2ee3d.pdf' -O 'data/meta_10k_filings.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing files: 100%|██████████| 1/1 [00:08<00:00,  8.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 pages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Initially I used SimpleDirectoryReader from llama_index.core but parser has a method to load data from a file.\n",
    "#sync\n",
    "documents = parser.load_data([\"./data/meta_10k_filings.pdf\"]) # keeping documents to mention corpus & remember there cna be multiple docs. \n",
    "print(f\"Loaded {len(documents)} document(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "## SECURITIES AND EXCHANGE COMMISSION UNITED STATES Washington, D.C. 20549\n",
      "\n",
      "## FORM 10-K\n",
      "\n",
      "(Mark One)\n",
      "\n",
      "☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "\n",
      "For the fiscal year ended December or 31, 2023\n",
      "\n",
      "☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "\n",
      "For the transition period from to\n",
      "\n",
      "Commission File Number: 001-35551\n",
      "\n",
      "Meta Platforms, Inc. Meta\n",
      "\n",
      "(Exact name of registrant as specified in its charter)\n",
      "\n",
      "Delaware 20-16650\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\") #list just like movies!!!\n",
    "print(type(documents[0])) # type document\n",
    "print(documents[0].text[:500]) # shows the markdown text of the document. Good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlamaIndex Recursive Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\") # Will change to 4 in prod. \n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Parsing aka without parsing instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "\n",
    "node_parser = MarkdownElementNodeParser(llm=OpenAI(model=\"gpt-3.5-turbo\"), num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "129it [00:00, 37176.39it/s]\n",
      "100%|██████████| 129/129 [00:34<00:00,  3.77it/s]\n"
     ]
    }
   ],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(documents=[documents[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing with Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parsingInstruction10K = \"\"\"\n",
    "The provided document is a 10K filing that contains various sections of text and tables. Parse the document as follows:\n",
    "\n",
    "Signature Table:\n",
    "\n",
    "Locate the table with columns for Signature, Title, and Date.\n",
    "Extract the data from each row of the table and create a structured Markdown table with the following columns: Name, Title, and Date.\n",
    "For the Name column, remove any signature prefixes (e.g., '/s/' or '/s') and only include the actual name.\n",
    "Preserve the original titles and dates as they appear in the table.\n",
    "The resulting Markdown table should be formatted properly with pipes (|) separating the columns and dashes (-) separating the header row from the data rows.\n",
    "\n",
    "\n",
    "Other Sections:\n",
    "\n",
    "Identify and extract the main sections of the document, such as the introduction, business description, risk factors, financial statements, etc.\n",
    "For each section, create a Markdown heading with the section title.\n",
    "Extract the text content of each section and include it under the corresponding heading.\n",
    "If a section contains subsections, create subheadings for each subsection and include the relevant text content.\n",
    "Preserve the original formatting of the text, such as paragraphs, lists, and tables, as much as possible.\n",
    "\n",
    "\n",
    "Output:\n",
    "\n",
    "Combine the parsed signature table and the other sections into a single Markdown document.\n",
    "Ensure that the signature table appears at the appropriate location within the document, typically towards the end.\n",
    "Use proper Markdown syntax for headings, subheadings, paragraphs, lists, tables, and any other formatting elements.\n",
    "The final output should be a well-structured Markdown representation of the entire 10K document, including the signature table and all other relevant sections.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The provided document contains a table listing signatures, titles, and dates. Extract the data from this table and create a Markdown table with the following columns: Name, Title, and Date. For the Name column, remove any signature prefixes (e.g., '/s/' or '/s') and only include the actual name. Preserve the original titles and dates as they appear in the image. The resulting Markdown table should be formatted properly with pipes (|) separating the columns and dashes (-) separating the header row from the data rows.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id dc418bf5-b0c0-4f66-a670-d82694b0e588\n",
      ".................."
     ]
    }
   ],
   "source": [
    "parsingInstructionMeta = \"\"\"The provided document contains a table listing signatures, titles, and dates. Extract the data from this table and create a Markdown table with the following columns: Name, Title, and Date. For the Name column, remove any signature prefixes (e.g., '/s/' or '/s') and only include the actual name. Preserve the original titles and dates as they appear in the image. The resulting Markdown table should be formatted properly with pipes (|) separating the columns and dashes (-) separating the header row from the data rows.\"\"\"\n",
    "withInstructionParsing = LlamaParse(\n",
    "    result_type=\"markdown\", parsing_instruction=parsingInstructionMeta\n",
    ").load_data(\"/Users/acrobat/Documents/GitHub/AI-Engineering-Cohort-2/midterm/data/meta_10k_filings.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "| Name | Title | Date |\n",
      "|------|-------|------|\n",
      "| SECURITIES AND EXCHANGE COMMISSION UNITED STATES | Washington, D.C. 20549 | - |\n",
      "| FORM 10-K | - | - |\n",
      "| Meta Platforms, Inc. Meta | Delaware 20-1665019 | - |\n",
      "| Class A Common Stock, $0.000006 par value | META | The Nasdaq Stock Market LLC |\n",
      "---\n",
      "| Name | Title | Date |\n",
      "|------|-------|------|\n",
      "|       |       |      |\n",
      "|       |       |      |\n",
      "|       |       |      |\n",
      "|       |       |      |\n",
      "|       |       |      |\n",
      "---\n",
      "| Name | Title | Date |\n",
      "|---\n"
     ]
    }
   ],
   "source": [
    "print(type(withInstructionParsing), \"\\n\") #list just like movies!!!\n",
    "print(type(withInstructionParsing[0])) # type document\n",
    "print(withInstructionParsing[0].text[:500]) # shows the markdown text of the document. Good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Name              | Title                                     | Date            |\n",
      "|-------------------|-------------------------------------------|-----------------|\n",
      "| Mark Zuckerberg   | Board Chair and Chief Executive Officer  | February 1, 2024 |\n",
      "| Susan Li          | Chief Financial Officer                   | February 1, 2024 |\n",
      "| Aaron Anderson    | Chief Accounting Officer                  | February 1, 2024 |\n",
      "| Peggy Alford      | Director                                  | February 1, 2024 |\n",
      "| Marc L. Andreessen| Director                                  | February 1, 2024 |\n",
      "| Andrew W. Houston | Director                                  | February 1, 2024 |\n",
      "| Nancy Killefer    | Director                                  | February 1, 2024 |\n",
      "| Robert M. Kimmitt | Director                                  | February 1, 2024 |\n",
      "| Sheryl K. Sandberg | Director                                 | February 1, 2024 |\n",
      "| Tracey T. Travis  | Director                                  | February 1, 2024 |\n",
      "| Tony Xu           | Director                                  | February 1, 2024 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_page = 133\n",
    "\n",
    "print(withInstructionParsing[0].text.split(\"\\n---\\n\")[target_page])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Name | Title | Date |\n",
      "|------|-------|------|\n",
      "| Directors, Executive Officers and Corporate Governance | The information required by this item is incorporated by reference to our Proxy Statement for the 2024 Annual Meeting of Stockholders to be filed with the SEC within 120 days of the fiscal year ended December 31, 2023. | - |\n",
      "| Executive Compensation | The information required by this item is incorporated by reference to our Proxy Statement for the 2024 Annual Meeting of Stockholders to be filed with the SEC within 120 days of the fiscal year ended December 31, 2023. | - |\n",
      "| Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters | The information required by this item is incorporated by reference to our Proxy Statement for the 2024 Annual Meeting of Stockholders to be filed with the SEC within 120 days of the fiscal year ended December 31, 2023. | - |\n",
      "| Certain Relationships and Related Transactions, and Director Independence | The information required by this item is incorporated by reference to our Proxy Statement for the 2024 Annual Meeting of Stockholders to be filed with the SEC within 120 days of the fiscal year ended December 31, 2023. | - |\n",
      "| Principal Accountant Fees and Services | The information required by this item is incorporated by reference to our Proxy Statement for the 2024 Annual Meeting of Stockholders to be filed with the SEC within 120 days of the fiscal year ended December 31, 2023. | - |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_page = 128\n",
    "\n",
    "print(withInstructionParsing[0].text.split(\"\\n---\\n\")[target_page])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Name | Title | Date |\n",
      "|------|-------|------|\n",
      "| Net income | $39,098 | $23,200 | $39,370 |\n",
      "| Depreciation and amortization | $11,178 | $8,686 | $7,967 |\n",
      "| Share-based compensation | $14,027 | $11,992 | $9,164 |\n",
      "| Deferred income taxes | $131 | ($3,286) | $609 |\n",
      "| Impairment charges for facilities consolidation, net | $2,432 | $2,218 | — |\n",
      "| Data center assets abandonment | ($224) | $1,341 | — |\n",
      "| Other | $635 | $641 | ($127) |\n",
      "| Accounts receivable | ($2,399) | $231 | ($3,110) |\n",
      "| Prepaid expenses and other current assets | $559 | $162 | ($1,750) |\n",
      "| Other assets | ($80) | ($106) | ($349) |\n",
      "| Accounts payable | $51 | $210 | $1,436 |\n",
      "| Partners payable | ($271) | $90 | ($12) |\n",
      "| Accrued expenses and other current liabilities | $5,352 | $4,210 | $3,544 |\n",
      "| Other liabilities | $624 | $886 | $941 |\n",
      "| Purchases of property and equipment | ($27,266) | ($31,431) | ($18,690) |\n",
      "| Proceeds relating to property and equipment | $221 | $245 | $123 |\n",
      "| Purchases of marketable debt securities | ($2,982) | ($9,626) | ($30,407) |\n",
      "| Sales and maturities of marketable debt securities | $6,184 | $13,158 | $42,586 |\n",
      "| Acquisitions of businesses and intangible assets | ($629) | ($1,312) | ($851) |\n",
      "| Other investing activities | ($23) | ($4) | ($331) |\n",
      "| Taxes paid related to net share settlement of equity awards | ($7,012) | ($3,595) | ($5,515) |\n",
      "| Repurchases of Class A common stock | ($19,774) | ($27,956) | ($44,537) |\n",
      "| Proceeds from issuance of long-term debt, net | $8,455 | $9,921 | — |\n",
      "| Principal payments on finance leases | ($1,058) | ($850) | ($677) |\n",
      "| Other financing activities | ($111) | $344 | $1 |\n",
      "| Effect of exchange rate changes on cash, cash equivalents, and restricted cash | $113 | ($638) | ($474) |\n",
      "| Net increase (decrease) in cash, cash equivalents, and restricted cash | $27,231 | ($1,269) | ($1,089) |\n",
      "| Cash, cash equivalents, and restricted cash at beginning of the period | $15,596 | $16,865 | $17,954 |\n",
      "| Cash, cash equivalents, and restricted cash at end of the period | $42,827 | $15,596 | $16,865 |\n",
      "| Cash and cash equivalents | $41,862 | $14,681 | $16,601 |\n",
      "| Restricted cash, included in prepaid expenses and other current assets | $99 | $294 | $149 |\n",
      "| Restricted cash, included in other assets | $866 | $621 | $115 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_page = 94\n",
    "\n",
    "print(withInstructionParsing[0].text.split(\"\\n---\\n\")[target_page])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143it [00:00, 51907.01it/s]\n",
      "100%|██████████| 143/143 [00:28<00:00,  5.10it/s]\n"
     ]
    }
   ],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(withInstructionParsing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the  Index (But where? I need this to be in Qdrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "recursive_index = VectorStoreIndex(nodes=base_nodes+objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastembed 0.2.6 requires huggingface-hub<0.21,>=0.20, but you have huggingface-hub 0.22.2 which is incompatible.\n",
      "fastembed 0.2.6 requires tokenizers<0.16.0,>=0.15.1, but you have tokenizers 0.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU llama-index-postprocessor-flag-embedding-reranker git+https://github.com/FlagOpen/FlagEmbedding.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! pip install huggingface-hub==0.20.0\n",
    "! pip install tokenizers==0.15.1\n",
    "! pip install -qU llama-index-postprocessor-flag-embedding-reranker git+https://github.com/FlagOpen/FlagEmbedding.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the reranker - we'll be leveraging this repo to leverage our BAAI/bge-reranker-large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.flag_embedding_reranker import FlagEmbeddingReranker\n",
    "\n",
    "reranker = FlagEmbeddingReranker(\n",
    "    top_n=5, # retun 5 from 15\n",
    "    model=\"BAAI/bge-reranker-large\",\n",
    ")\n",
    "\n",
    "recursive_query_engine = recursive_index.as_query_engine(\n",
    "    similarity_top_k=15,  #grab 15 top results\n",
    "    node_postprocessors=[reranker],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;11;159;203mRetrieval entering d11e66f0-2353-49b9-b04a-919eddaea8be: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 4c132dfe-5f9a-4a90-b861-dc431eb0201a: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 1cd2e147-dca5-428a-a619-717dea634e79: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 5a3aca44-baf6-4000-bdbc-45e5cd0bee25: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 019a36f8-cce1-495f-8fd8-3b51866d0c82: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering a6b5acd4-6e91-40fe-90d0-a058ce478c33: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 74e9d254-c6d5-41c1-872b-54a62d5c1124: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 71e341b5-e991-4fa0-a76f-ec2648b123a3: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 9577de1d-9bf9-4123-a5e5-21091d5a18b5: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 0b336bc6-6012-4652-9fb1-79e9e74a99f6: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering c21916fb-27cf-4e7a-bf1b-340c032b190c: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering dfc7368d-75e5-43bf-b96d-13d638d87f52: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering ad84d99b-d570-4251-82e3-5d09aa92cba2: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 3e7be0e5-6897-4c26-a892-90e4943f7747: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "query = \"What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\"\n",
    "response = recursive_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total value of 'Cash and cash equivalents' as of December 31, 2023, was $41,862 million.\n"
     ]
    }
   ],
   "source": [
    "print(response) #yippee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;11;159;203mRetrieval entering a40539d4-071f-4d27-a46f-e423d519121a: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 58615add-efe0-4cec-9d91-c35b39f1a9ca: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 8c1fa50e-8334-4e87-9288-3bd9b0a0401e: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 286c96d2-4d42-491a-a50e-c4befbd3d482: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering bbe854f9-3032-4cda-a758-8193c2b1cca4: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 36e772df-fa7b-4b29-8736-2691fa4eaf42: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 90c9631a-ba7d-484f-a9c5-0c3dfe18eb1b: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 0bfa6204-313d-455c-9a8d-11c4bef6481d: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering d4f847e7-fcb6-4d2f-abda-d988f2f547e3: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 77619f22-6592-4971-aa78-997098d32624: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering d12b47d9-f0b8-4535-952f-05c26e808efe: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 1ea1afc4-1356-4805-a8b1-4736f5e47b7a: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 43c94b1d-8235-414b-97b3-48a4ebbb3ea9: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 1224bf2c-81d4-4221-85f9-786d4e18e718: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 94b3af83-39c2-4a79-8218-6c2925a8f99c: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "query = \"What are the names of people with the director title at Meta?\"\n",
    "#query = \"What are the names of people with the title = Director at Meta?\"\n",
    "response = recursive_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peggy Alford, Marc L. Andreessen, Andrew W. Houston, Nancy Killefer, Robert M. Kimmitt, Sheryl K. Sandberg, Tracey T. Travis, Tony Xu\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;11;159;203mRetrieval entering c008b47d-7f6d-4564-bc4b-5bd875d7b22e: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering a4d826f2-dbe8-432d-9afb-21968026d1b3: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering df68930f-ce97-4f09-b325-4d212959f700: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 3e7be0e5-6897-4c26-a892-90e4943f7747: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 5a3aca44-baf6-4000-bdbc-45e5cd0bee25: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 4c132dfe-5f9a-4a90-b861-dc431eb0201a: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 2423f18b-3ea0-4d16-a703-5061409a32c9: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 019a36f8-cce1-495f-8fd8-3b51866d0c82: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering bd6d089a-20da-4e68-a6dd-5c3404c77886: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 7772ddc9-e4ea-460f-bcce-4ffa687dfd4b: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering d11e66f0-2353-49b9-b04a-919eddaea8be: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering eecc8ee4-1a20-4e8c-880b-c95dc53b88b9: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 1cd2e147-dca5-428a-a619-717dea634e79: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 74e9d254-c6d5-41c1-872b-54a62d5c1124: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What is the value of total defferred tax liabilities in year 2023?\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"What is the value of total defferred tax liabilities in year 2023?\"\n",
    "response = recursive_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of total deferred tax liabilities in year 2023 is ($11,028) million.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = OpenAI(temperature=0.2, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a folder and then download and update its name:\n",
    "!mkdir -p 'data/'\n",
    "!wget 'https://d18rn0p25nwr6d.cloudfront.net/CIK-0001326801/c7318154-f6ae-4866-89fa-f0c589f2ee3d.pdf' -O 'data/meta_10k_filings.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/meta_10k_filings.pdf\"]\n",
    ")\n",
    "\n",
    "documents = reader.load_data()\n",
    "print(f\"Loaded {len(documents)} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_docs = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/meta_10k_filings.pdf\"]\n",
    ").load_data()\n",
    "# uber_docs = SimpleDirectoryReader(\n",
    "#     input_files=[\"./data/10k/uber_2021.pdf\"]\n",
    "# ).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_index = VectorStoreIndex.from_documents(meta_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_engine = meta_index.as_query_engine(similarity_top_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=meta_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"meta_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Meta FORM 10-K\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    # QueryEngineTool(\n",
    "    #     query_engine=uber_engine,\n",
    "    #     metadata=ToolMetadata(\n",
    "    #         name=\"uber_10k\",\n",
    "    #         description=(\n",
    "    #             \"Provides information about Uber financials for year 2021\"\n",
    "    #         ),\n",
    "    #     ),\n",
    "    # ),\n",
    "]\n",
    "\n",
    "s_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[meta_10k] Q: What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[meta_10k] A: The total value of 'Cash and cash equivalents' as of December 31, 2023, was $65.40 billion.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = s_engine.query(\n",
    "\"What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[meta_10k] Q: What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[meta_10k] A: The names of people with the director title at Meta are not provided in the given context information.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = s_engine.query(\n",
    "\"What are the names of people with the director title at Meta?\"\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex_env",
   "language": "python",
   "name": "llamaindex_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
