{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Instructions:\n",
    "__Data__: Meta 10-k Filings\\\n",
    "__LLM__: OpenAI GPT-3.5-turbo\\\n",
    "__Embedding Model__: text-3-embedding small\\\n",
    "__Infrastructure__: LlamaIndex\\\n",
    "__Vector Store__: Qdrant - Stored in the db\\\n",
    "__Deployment__: Chainlit, Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I used llama Cloud Parse with parsing instructions and persisted data in a Qdrand Vector DB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install llama-index\n",
    "%pip install llama-index-core\n",
    "%pip install llama-index-embeddings-openai\n",
    "%pip install llama-index-postprocessor-flag-embedding-reranker\n",
    "%pip install git+https://github.com/FlagOpen/FlagEmbedding.git\n",
    "%pip install llama-parse\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a data folder and then download the document while updating its name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/'\n",
    "!wget 'https://d18rn0p25nwr6d.cloudfront.net/CIK-0001326801/c7318154-f6ae-4866-89fa-f0c589f2ee3d.pdf' -O 'data/meta_10k_filings.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you are in a Jupyter Notebook - I did.\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API keys for OpenAI and Llamda Cloud & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "llama_cloud_api_key = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)   # I used the updated GPT-3.5 model since current 3.5 points to 0613 and will be depreciated. \n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing with Instructions:  -- update!!!\n",
    "Ref: https://github.com/run-llama/llama_parse/blob/main/examples/demo_parsing_instructions.ipynb\n",
    "\n",
    "Instead of vanialla parsing I decide to use a prompt in my parsing. I saw the option in LlamaParse website: https://cloud.llamaindex.ai/parse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below instructions did the job however it also added name, title and dates randomly. This did not impact the end results. I am able to return answers correctly to assignment questions as well any other question I have tested. Ideally I need to tailor the instructions to avoid the unnecessary add ons and make it suitable for any and every 10k document.\n",
    "\n",
    "- To create tailored template I can feed in specific non text pages to llama parse website and tailor a prompt for each page then combine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id a641e61d-bafb-4c13-8141-4d1fa722a55c\n",
      "......................"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "parsingInstructionMeta = \"\"\"The provided document contains a table listing signatures, titles, and dates. Extract the data from this table and create a Markdown table with the following columns: Name, Title, and Date. For the Name column, remove any signature prefixes (e.g., '/s/' or '/s') and only include the actual name. Preserve the original titles and dates as they appear in the image. The resulting Markdown table should be formatted properly with pipes (|) separating the columns and dashes (-) separating the header row from the data rows.\"\"\"\n",
    "\n",
    "documents = LlamaParse(\n",
    "    result_type=\"markdown\", parsing_instruction=parsingInstructionMeta\n",
    ").load_data(\"/Users/acrobat/Documents/GitHub/AI-Engineering-Cohort-2/midterm/data/meta_10k_filings.pdf\")\n",
    "\n",
    "# As Chris mentioned there has to be caching at llamaCloud side. My first instruction_parsing run took over 20mins however subsequent ones were under 10 seconds.\n",
    "# However when I restart the notebook we are back to almost 10 mins run time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Power of attorney table markdown - Check the instruction parsing page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```markdown\n",
      "| Name              | Title                                     | Date            |\n",
      "|-------------------|-------------------------------------------|-----------------|\n",
      "| Mark Zuckerberg   | Board Chair and Chief Executive Officer   | February 1, 2024 |\n",
      "| Susan Li          | Chief Financial Officer                   | February 1, 2024 |\n",
      "| Aaron Anderson    | Chief Accounting Officer                  | February 1, 2024 |\n",
      "| Peggy Alford      | Director                                  | February 1, 2024 |\n",
      "| Marc L. Andreessen| Director                                  | February 1, 2024 |\n",
      "| Andrew W. Houston | Director                                  | February 1, 2024 |\n",
      "| Nancy Killefer    | Director                                  | February 1, 2024 |\n",
      "| Robert M. Kimmitt | Director                                  | February 1, 2024 |\n",
      "| Sheryl K. Sandberg | Director                                 | February 1, 2024 |\n",
      "| Tracey T. Travis  | Director                                  | February 1, 2024 |\n",
      "| Tony Xu           | Director                                  | February 1, 2024 |\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "target_page = 132 # I noticed the md also changes the number of pages. The time I was querying 133 now 132. :)\n",
    "print(documents[0].text.split(\"\\n---\\n\")[target_page]) # works like a champ!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em 1B. | 51 |\n",
      "| Cybersecurity | Item 1C. | 51 |\n",
      "| Properties | Item 2. | 52 |\n",
      "| Legal Proceedings | Item 3. | 52 |\n",
      "| Mine Safety Disclosures | Item 4. | 56 |\n",
      "| Market for Registrant's Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities | Item 5. | 57 |\n",
      "| [Reserved] | Item 6. | 58 |\n",
      "| Management's Discussion and Analysis of Financial Condition and Results of Operations | Item 7. | 59 |\n",
      "| Quantitative and Qualitative Disclosures About Market Risk | Item 7A. | 82 |\n",
      "| Financial Statements and Supplementary Data | Item 8. | 84 |\n",
      "| Changes in and Disagreements with Accountants on Accounting and Financial Disclosure | Item 9. | 126 |\n",
      "| Controls and Procedures | Item 9A. | 126 |\n",
      "| Other Information | Item 9B. | 126 |\n",
      "| Disclosure Regarding Foreign Jurisdictions that Prevent Inspections | Item 9C. | 126 |\n",
      "| Directors, Executive Officers and Corporate Governance | Item 10. | 127 |\n",
      "| Executive Compensation | Item 11. | 127 |\n",
      "| Security Ownership of Certain Benefic...\n"
     ]
    }
   ],
   "source": [
    "# Check rest of the document. \n",
    "print(documents[0].text[1000:2000] + \"...\") # one thing to notice is that the text is not in the same order as the original document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown parser & node construction - need it because of recursive retriever\n",
    "At this point all i have is a markdown doc parsed from the pdf and stored in the documents variable.  Using MarkdownElementNodeParser for parsing the LlamaParse output Markdown results and building recursive retriever query engine for generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "\n",
    "node_parser = MarkdownElementNodeParser(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo-0125\"), num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "147it [00:00, 51509.00it/s]\n",
      "100%|██████████| 147/147 [00:41<00:00,  3.55it/s]\n"
     ]
    }
   ],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes)) # recursive_index - query 428 nodes. We want nodes thinking it will be more precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(documents)) # raw_index - query 1 document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbase_nodes\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext) \u001b[38;5;66;03m# This is the first node.\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'base_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "print(base_nodes[0].text) # This is the first node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the `VectorStoreIndex` with QDrant and create collection meta_10k_filings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data in Qdrand memory - To check how memory would work but decided on materializing in Qdrand since I dont want o parse and also keep documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(location=\":memory:\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"meta_10k_filings\",\n",
    "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist data in Qdrant DB - client = qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully to the Qdrant vector database.\n"
     ]
    }
   ],
   "source": [
    "# connect the db\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://24f997d6-02df-4889-a352-1eac83e0bd37.us-east4-0.gcp.cloud.qdrant.io:6333\", \n",
    "    api_key=os.environ[\"QDRANT_API_KEY\"],\n",
    ")\n",
    "\n",
    "try:\n",
    "    collections = qdrant_client.get_collections()\n",
    "    print(\"Connected successfully to the Qdrant vector database.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to the Qdrant vector database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='meta_10k_filingsV6'), CollectionDescription(name='meta_10k_filingsV3'), CollectionDescription(name='meta_10k_filingsV4'), CollectionDescription(name='meta_10k_filingsV8'), CollectionDescription(name='meta_10k_filings'), CollectionDescription(name='meta_10k_filingsV9'), CollectionDescription(name='meta_10k_filingsV5'), CollectionDescription(name='meta_10k_filingsV2'), CollectionDescription(name='meta_10k_filingsV7')]\n"
     ]
    }
   ],
   "source": [
    "collections = qdrant_client.get_collections()\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load nodes to Qdrant to create the recursive_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Recursive Index - Will use recursive index instead of simple index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://24f997d6-02df-4889-a352-1eac83e0bd37.us-east4-0.gcp.cloud.qdrant.io:6333\", \n",
    "    api_key=os.environ[\"QDRANT_API_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    collection_name=\"meta_10k_filingsV4\",\n",
    "    client=qdrant_client,\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total value of 'Cash and cash equivalents' as of December 31, 2023 was $33,334.\n"
     ]
    }
   ],
   "source": [
    "print(response) # not correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What are the names of people with the director title at Meta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life@ Meta\n"
     ]
    }
   ],
   "source": [
    "print(response) # not correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    collection_name=\"meta_10k_filingsV5\",\n",
    "    client=qdrant_client,\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex(\n",
    "    nodes=nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=OpenAIEmbedding(),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total value of 'Cash and cash equivalents' as of December 31, 2023 was included in the financial data breakdown for that date.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What are the names of people with the director title at Meta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board Members and Executives of a Company\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    collection_name=\"meta_10k_filingsV9\",\n",
    "    client=qdrant_client,\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex(\n",
    "    nodes=base_nodes + objects,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=OpenAIEmbedding(model=\"text-embedding-3-small\"),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What are the names of people with the director title at Meta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total value of 'Cash and cash equivalents' as of December 31, 2023 was not provided in the context information.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import ServiceContext\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1_/5w1dty5j7nx2sk_l039y73900000gn/T/ipykernel_17794/1883827176.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=embed_model,\n",
    "    node_parser=node_parser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import Document\n",
    "for document in documents:\n",
    "    index.insert(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1_/5w1dty5j7nx2sk_l039y73900000gn/T/ipykernel_17794/1066332197.py:10: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient, models\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import ServiceContext\n",
    "\n",
    "\n",
    "vector_store = QdrantVectorStore(client=qdrant_client, collection_name=\"meta_10k_filingsV2\")  # client = qudrant_client\n",
    "\n",
    "# define chuncking startegy and embedding model\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    #embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "\n",
    "node_parser = MarkdownElementNodeParser(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo-0125\"), num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=\"local:BAAI/bge-large-en-v1.5\",\n",
    "    node_parser=node_parser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "recursive_index = VectorStoreIndex(\n",
    "    nodes=base_nodes + objects, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llama_index.vector_stores.qdrant.base.QdrantVectorStore'>\n"
     ]
    }
   ],
   "source": [
    "print(type(vector_store)) # check what is the vectorstore, pheww!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the reranker \n",
    "- initialluild with BAAI/bge-reranker-large. It takes about 3-5 secs for each question. \n",
    "In HF website I see other options: For better performance, recommand BAAI/bge-reranker-v2-minicpm-layerwise and BAAI/bge-reranker-v2-gemma. So I used gemma and crashed my computer. Then I realized it is 2.8B parameters. Sticking with reranker-large.  \n",
    "https://huggingface.co/BAAI/bge-reranker-v2-m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.flag_embedding_reranker import (\n",
    "    FlagEmbeddingReranker,\n",
    ")\n",
    "\n",
    "reranker = FlagEmbeddingReranker(\n",
    "    top_n=5,\n",
    "    model=\"BAAI/bge-reranker-large\",\n",
    ")\n",
    "\n",
    "recursive_query_engine = recursive_index.as_query_engine(\n",
    "    similarity_top_k=15, node_postprocessors=[reranker], verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 8858f292-49fb-497f-b2f9-c42faecd60f9: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 981b39e8-3498-456f-a0ad-f78ee1090706: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 409e93db-2164-4ded-9eb4-d2c0caf7b1fb: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering c92bf696-a102-465a-9f04-9ec11fa86fdf: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 84a2fb6d-7e2d-4616-9ad6-212ec6ca2a18: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 1bf2f2e3-5aa4-45ac-958c-b119cfb974ab: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering b7f923fb-f4ee-479a-8b62-8e895aecef75: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 077aac53-d4a8-48b6-b227-4bd8137b5e97: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering c4d9072f-e8aa-4e66-8be6-0a0c49fb147e: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 74bcf61d-ed93-478f-a924-3d3e4e2dcaed: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 5cc79511-02b3-4767-aaf3-5a93ed6638e0: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 8621e2b6-bcde-4382-a35e-bd75a6a71da2: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 6af4c943-0d6e-45b7-8db5-377baca1ae4b: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering b33cc556-f200-4159-b903-8f572cf50dd1: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering fe260eea-e906-44bc-ada2-d4d6f8b9161b: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "query = \"What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\"\n",
    "response = recursive_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total value of 'Cash and cash equivalents' as of December 31, 2023, was $41,862 million.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 248c8a12-12c0-4957-b5b7-a4325579b216: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering badfca08-b294-4f2a-81d6-87fb17989c5e: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering b3638b29-4431-41ce-a157-85547ab29073: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 77c1290f-d5ae-43a1-8373-e38271b24a64: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 50247b25-e48b-4a61-8f21-ed2f7356ea55: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 62a2fbe9-06f1-4a46-a5f8-42f29066db03: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering cb174518-1dc0-4713-b263-c105b130885c: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 884b2ad4-fdd4-44a8-8561-fcd7f14dc2da: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 5a7458fb-bca3-46cd-95f1-6facd243aa0d: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 2ddcf8e0-211e-4364-86de-dbe9dcbf79f9: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 9b3e9d74-199e-4a61-b2ae-a5aa6d1cf063: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 3a14e286-99c4-407b-9bb0-d654dd0909fa: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering c4d9072f-e8aa-4e66-8be6-0a0c49fb147e: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 67454a6b-e25a-4f18-8081-da030f3493a4: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering b444f164-3bc9-4b93-931e-f0d81620e201: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the names of people with the director title at Meta?\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "query = \"What are the names of people with the director title at Meta?\"\n",
    "response = recursive_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peggy Alford, Marc L. Andreessen, Andrew W. Houston, Nancy Killefer, Robert M. Kimmitt, Sheryl K. Sandberg, Tracey T. Travis, Tony Xu.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 85d70991-2391-41e8-8022-e0a53f900ec7: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering a8078aaa-bc49-4d55-b7ef-6759995f7178: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering e3037d05-7dc2-490d-90f5-1b3841d44851: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 14b05db9-b086-4b8b-b72b-7d22ec8001c2: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 344ccda5-1ef0-45cb-95fa-97052beef754: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 62a2fbe9-06f1-4a46-a5f8-42f29066db03: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering e545fbe8-b944-49bf-98e3-ccbf5a3b1b12: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering ba48ea7e-3f4e-4a1a-b63f-e6aec5374596: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering de3905a4-304b-4199-a284-60bafcfff892: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 45e9f143-c53a-444f-9f57-5a0294906ca0: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 4d290b84-1ffa-49b0-86b2-ae45c85a7f2f: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering ec94b2d8-7fcc-4c65-8e4e-a43a33ce7978: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 7775fa85-b531-4b2e-a75d-f5d289629801: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 76828ed7-2de5-440c-bf9e-71f7fd6dee4b: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering d360c181-2592-4961-9ac1-1991ccd20414: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query What are the main sections of the document?\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "query = \"What are the main sections of the document?\"\n",
    "response = recursive_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main sections of the document include government regulations, court decisions, and official actions related to data protection and privacy; sections related to corporate governance, executive compensation, security ownership, relationships and transactions, and accountant fees for the 2024 Annual Meeting of Stockholders; various sections of a financial report such as balance sheets, statements of income, stockholders' equity, cash flows, and notes to financial statements; and information on agreements and plans related to executive compensation and operations.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;11;159;203mRetrieval entering 25116ea7-3ebe-4ad9-9d39-74e4b319d968: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering e545fbe8-b944-49bf-98e3-ccbf5a3b1b12: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 04aa459d-4aad-44df-bd92-7085d0ffb573: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 54d711c3-d2d0-43e5-a30b-2654b9ffb8e5: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering c8a3588b-467a-4e4c-89de-7ad7d368095c: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 9c442e29-7b3f-45fd-8e99-a6ceb6cb88fa: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 35689b94-b3c6-4804-80a7-6b6c3f12cc5f: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering e3037d05-7dc2-490d-90f5-1b3841d44851: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 45e9f143-c53a-444f-9f57-5a0294906ca0: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 24151d39-3b6f-42d8-86a4-c3032c1f7657: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 7de5db5f-7813-4420-b8f6-65d7d3dfbbcc: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 67d02e85-d3ba-46f0-9c50-9c5054851de8: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 1b7d129a-a484-4ce6-99aa-1c4a8be8ce75: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 14b05db9-b086-4b8b-b72b-7d22ec8001c2: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 3918a305-01d6-414d-8100-755eeec09df8: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query List me the table of contents?\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "query = \"List me the table of contents?\"\n",
    "response = recursive_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table of contents includes the following tables:\n",
      "1. Financial Items Table\n",
      "2. Corporate Governance Provisions Table\n",
      "3. Corporate Governance Topics Table\n",
      "4. Individual Information Table (Empty)\n",
      "5. Individual Information Table with Guy Rosen's Information\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;11;159;203mRetrieval entering e3037d05-7dc2-490d-90f5-1b3841d44851: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering dce35d54-eac3-41e0-b2bf-7074c0cc576f: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 62a2fbe9-06f1-4a46-a5f8-42f29066db03: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering e545fbe8-b944-49bf-98e3-ccbf5a3b1b12: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering ba48ea7e-3f4e-4a1a-b63f-e6aec5374596: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 344ccda5-1ef0-45cb-95fa-97052beef754: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 85d70991-2391-41e8-8022-e0a53f900ec7: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering a8078aaa-bc49-4d55-b7ef-6759995f7178: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 14b05db9-b086-4b8b-b72b-7d22ec8001c2: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 3918a305-01d6-414d-8100-755eeec09df8: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 80349760-3bef-49d7-bd51-d4ee0a15c176: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 45e9f143-c53a-444f-9f57-5a0294906ca0: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 1ae2b16d-3be2-46a0-b39a-7444e9bef6a8: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 76828ed7-2de5-440c-bf9e-71f7fd6dee4b: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 81eb49f9-6467-40b1-99c2-c444ec05cd4e: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query How many pages are in the document?\n",
      "\u001b[0mThe document consists of multiple sections, each with its own content. The total number of pages in the document cannot be determined based on the provided context information.\n"
     ]
    }
   ],
   "source": [
    "response = recursive_query_engine.query(\n",
    "    \"How many pages are in the document?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay now we are using Qdrand to answer the questions. The pdf is loaded to the Qdrand collection. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex_env",
   "language": "python",
   "name": "llamaindex_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
