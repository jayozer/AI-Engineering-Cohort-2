{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgDepNVhvzIr"
      },
      "source": [
        "# OpenAI Assistants - Building Agentic RAG with the Function Calling, Retrieval, and Code Interpreter Tools\n",
        "\n",
        "Today we'll explore using OpenAI's Python SDK to create, manage, and use the OpenAI Assistant API!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jay: OpenAI(): This is likely the standard, synchronous version. When you call a method on an instance of this class, the method runs to completion and returns a result. Your program waits for the method to finish before continuing.\n",
        "\n",
        "AsyncOpenAI(): This is likely the asynchronous version. When you call a method on an instance of this class, the method starts running but your program doesn't wait for it to finish. Instead, the method returns a \"future\" object that represents the result of the method. Your program can continue doing other things and check the result of the method later.\n",
        "\n",
        "In general, asynchronous programming can make your program more efficient by allowing it to do other things while waiting for slow operations (like network requests) to complete. However, it can also make your program more complex because you have to manage the \"futures\" and handle the possibility that operations might not complete in the order you started them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNU6b3ymwOWq"
      },
      "source": [
        "## Dependencies\n",
        "\n",
        "We'll start, as we usually do, with some dependiencies and our API key!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePayyL6at6LS"
      },
      "outputs": [],
      "source": [
        "!pip install -qU openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unKr3HZdu-1V",
        "outputId": "610aeddb-5e56-4d75-e399-59054435c2ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwNE7N4HwhXH"
      },
      "source": [
        "## Simple Assistant\n",
        "\n",
        "Let's create a simple Assistant to understand more about how the API works to start!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKEwbLMFxNKs"
      },
      "source": [
        "### OpenAI Client\n",
        "\n",
        "At the core of the OpenAI Python SDK is the Client!\n",
        "\n",
        "> NOTE: For ease of use, we'll start with the synchronous `OpenAI()`. OpenAI does provide an `AsyncOpenAI()` that you could leverage as well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wF-mBZwtuavl"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aIx4GZ2w_1c"
      },
      "source": [
        "### Creating An Assistant\n",
        "\n",
        "Leveraging what we know about the OpenAI API from previous sessions - we're going to start by simply initializing an Assistant.\n",
        "\n",
        "Before we begin, we need to think about a few customization options we have:\n",
        "\n",
        "- `name` - Straight forward enough, this is what our Assistant's name will be\n",
        "- `instructions` - similar to a system message, but applied at an Assistant level, this is how we can guide the Assistant's tone, behaviour, functionality, and more!\n",
        "- `model` - this will allow us to choose which model we would prefer to use for our Assistant\n",
        "\n",
        "Let's start by setting some instructions for our Assistant.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "Paqd6zWMyMAJ"
      },
      "outputs": [],
      "source": [
        "# @markdown #### üèóÔ∏è Build Activity üèóÔ∏è\n",
        "# @markdown Fill out the fields below to add your Assistant's name, instructions, and desired model!\n",
        "\n",
        "name = \"Poppy\" # @param {type: \"string\"}\n",
        "instructions = \"You are a helpful FAQ assistant specializing in pediatric dentistry. Keep your answers succinct, aiming for brevity with no more than two sentences per response.\" # @param {type: \"string\"}\n",
        "model = \"gpt-4-turbo\" # @param [\"gpt-3.5-turbo\", \"gpt-4-turbo-preview\", \"gpt-4\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jay: You will embody Poppy, an AI chat assistant specializing in pediatric dentistry FAQs. Your interactions should exude warmth and engagement, offering support and information to users with a friendly touch. Keep your answers succinct, aiming for brevity with no more than two sentences per response. Should a question fall outside your expertise, kindly inform the user, 'I‚Äôm sorry, but I can only provide information related to pediatric dentistry.' For unrelated inquiries, maintain your role by stating, 'As Poppy, your pediatric dentistry assistant, I'm here to help with questions about children's dental care only.' Your primary goal is to inform and assist within the scope of pediatric dentistry, ensuring a helpful and positive user experience.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUeaDsLMzcv-"
      },
      "source": [
        "### Initialize Assistant\n",
        "\n",
        "Now that we have our desired name, instruction, and model - we can initialize our Assistant!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6-4MgVLbu8rO"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=name,\n",
        "    instructions=instructions,\n",
        "    model=model,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QskO5n5W2X6t"
      },
      "source": [
        "Let's examine our `assistant` object and see what we find!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkkIC_JP2bG0",
        "outputId": "a1646ea4-dc68-4a3d-f997-c3e7f0fd7abd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Assistant(id='asst_eGgBBayHusd016cplTLvOJlr', created_at=1712893835, description=None, file_ids=[], instructions='You are a helpful FAQ assistant specializing in pediatric dentistry. Keep your answers succinct, aiming for brevity with no more than two sentences per response.', metadata={}, model='gpt-4-turbo', name='Poppy', object='assistant', tools=[])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assistant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "615NK1Qj2e_Z"
      },
      "source": [
        "There are a number of useful parameters here, but we'll call out a few:\n",
        "\n",
        "- `id` - since we may have multiple Assistant's, knowing which Assistant we're interacting with will help us ensure the desired user experience!\n",
        "- `description` - A natrual language description of our Assistant could help others understand what it's supposed to do!\n",
        "- `file_ids` - if we wanted to use the Retrieval tool, this would let us know what files we had given our Assistant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3HhlqtM0AhW"
      },
      "source": [
        "### Creating a Thread\n",
        "\n",
        "Behind the scenes our Assistant is powered by the idea of \"threads\".\n",
        "\n",
        "You can think of threads as individual conversations that interact with the Assistant.\n",
        "\n",
        "Let's create a thread now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iFVM39vevT5f"
      },
      "outputs": [],
      "source": [
        "thread = client.beta.threads.create()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y7jelq01PoG"
      },
      "source": [
        "Let's look at our `thread` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V8WAKDZ1Uf2",
        "outputId": "4678aaef-3c01-4876-8136-334897074ad7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Thread(id='thread_w2UnIiuXcXI4IoWCAxQxzeLT', created_at=1712927206, metadata={}, object='thread')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "thread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k6S_e501V4z"
      },
      "source": [
        "Notice some key attributes:\n",
        "\n",
        "- `id` - since each Thread is like a conversation, we need some way to specify which thread we're dealing with when interacting with them\n",
        "- `tool_resources` - this will become more relevant as we add tools since we'll need a way to verify which tools we have access to when interacting with our Assistant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5BvGv1N0c2h"
      },
      "source": [
        "### Adding Messages to Our Thread\n",
        "\n",
        "Now that we have our Thread (or conversation) we can start adding messages to it!\n",
        "\n",
        "Let's add a simple message that asks about how our Assistant is feeling.\n",
        "\n",
        "Notice the parameters we're leveraging:\n",
        "\n",
        "- `thread_id` - since each Thread is like a conversation, we need some way to address a specific conversation. We can use `thread.id` to do this.\n",
        "- `role` - similar to when we used our chat completions endpoint, this parameter specifies who the message is coming from. You can leverage this in the same ways you would through the chat completions endpoint.\n",
        "- `content` - this is where we can place the actual text our Assistant will interact with\n",
        "\n",
        "> NOTE: Feel free to substitute a relevant message based on the Assistant you created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "R7ZNCfGivagg"
      },
      "outputs": [],
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=f\"Why should I choose a pediatric dentist for my child over a geenral dentist?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc7R3Sr32P0b"
      },
      "source": [
        "Again, let's examine our `message` object!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMLvyZDA2S_D",
        "outputId": "5076c8e4-0970-44ff-c609-1501a53cfe1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Message(id='msg_RdsX8Jw76gkYX8Cuq7QwwTDT', assistant_id=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Why should I choose a pediatric dentist for my child over a geenral dentist?'), type='text')], created_at=1712927318, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_w2UnIiuXcXI4IoWCAxQxzeLT')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI3Pctpk29og"
      },
      "source": [
        "### Running Our Thread\n",
        "\n",
        "Now that we have an Assistant, and we've given that Assistant a Thread, and we've added a Message to that Thread - we're ready to run our Assistant!\n",
        "\n",
        "Notice that this process lets us add (potentially) multiple messages to our Assistant. We can leverage that behaviour for few/many-shot examples, and more!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jay: Analyze the question and chunks to determine if clarification is needed:\n",
        "\n",
        "Check query specificity and chunk scope.\n",
        "If query is broad or lacks essential details, output '#' and provide a clear explanation of the information needed for a comprehensive answer.\n",
        "If query matches a specific chunk that provides a complete answer, output '~'.\n",
        "Output: [Decision: '~' or '#'. If '#', provide a detailed clarification request specifying the information needed to answer the question effectively. Tailor the clarification to the specific query and context.]\n",
        "\n",
        "Example:\n",
        "Question: \"Should my child use an electric toothbrush?\"\n",
        "Output: [Decision: '#', Please provide the age of your child and any specific dental concerns or needs they may have. This information will help determine if an electric toothbrush is suitable for them.]\n",
        "\n",
        "Note: For age-specific or child's dental situation questions, always ask for clarification if essential details are not provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "VkvsXv5_3cyQ"
      },
      "outputs": [],
      "source": [
        "# @markdown #### üèóÔ∏è Build Activity üèóÔ∏è\n",
        "# @markdown We can also override the Assistant's instructions when we run a thread.\n",
        "\n",
        "# @markdown Use one of the [Prompt Principles for Instruction](https://arxiv.org/pdf/2312.16171v1.pdf) to improve the likeliehood of a correct or valuable response from your Assistant.\n",
        "\n",
        "additional_instructions = \"Your audience is the parents of children. Think step by step and sound confident in your replies.\" # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CuGbTrL5QEc"
      },
      "source": [
        "Let's run our Thread!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fpWNl3UVvdW4"
      },
      "outputs": [],
      "source": [
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        "  instructions=instructions + \" \" + additional_instructions\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are a helpful FAQ assistant specializing in pediatric dentistry. Keep your answers succinct, aiming for brevity with no more than two sentences per response. Your audience is the parents of children. Think step by step and sound confident in your replies.\n"
          ]
        }
      ],
      "source": [
        "#Jay:\n",
        "print(instructions + \" \" + additional_instructions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erMGdU7y6la2"
      },
      "source": [
        "Now that we've run our thread, let's look at the object!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz_rfwi869YI",
        "outputId": "9b0df335-c3a9-43a5-f7c0-020e37679c8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Run(id='run_Nq5fLRcpo49bkXzEgR7m6a9M', assistant_id='asst_eGgBBayHusd016cplTLvOJlr', cancelled_at=None, completed_at=None, created_at=1712928534, expires_at=1712929134, failed_at=None, file_ids=[], instructions='You are a helpful FAQ assistant specializing in pediatric dentistry. Keep your answers succinct, aiming for brevity with no more than two sentences per response. Your audience is the parents of children. Think step by step and sound confident in your replies.', last_error=None, metadata={}, model='gpt-4-turbo', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_w2UnIiuXcXI4IoWCAxQxzeLT', tools=[], usage=None, temperature=1.0)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h2SH_347JJb"
      },
      "source": [
        "Notice we have access to a few very powerful parameters in this `run` object.\n",
        "\n",
        "- `completed_at` - this will help us determine when we can expect to retrieve a response\n",
        "- `failed_at` - this can highlight any issues our run ran into\n",
        "- `status` - is another way we can understand how the flow is going"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVBNagBU7kpx"
      },
      "source": [
        "### Retrieving Our Run\n",
        "\n",
        "Now that we've created our run, let's retrieve it.\n",
        "\n",
        "We're going to wrap this in a simple loop to make sure we're not retrieving it too early."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "itz5_otPvfkV"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "while run.status == \"in_progress\" or run.status == \"queued\":\n",
        "  time.sleep(1)\n",
        "  run = client.beta.threads.runs.retrieve(\n",
        "    thread_id=thread.id,\n",
        "    run_id=run.id\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgGE1uUJ7z3h",
        "outputId": "174572f2-fcb6-4b5e-9ad0-6a6b9c413f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "completed\n"
          ]
        }
      ],
      "source": [
        "print(run.status)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHVTS4hD7-fv"
      },
      "source": [
        "Now that our run is completed - we can retieve the messages from our thread!\n",
        "\n",
        "Notice that our run helps us understand how things are going - but it isn't where we're going to find our responses or messages. Those are added on the backend into our thread.\n",
        "\n",
        "This leads to a simple, but important, flow:\n",
        "\n",
        "1. We add messages to a thread.\n",
        "2. We create a run on that thread.\n",
        "3. We wait until the run is finished.\n",
        "4. We check our thread for the new messages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGBNpGmh-ZpW"
      },
      "source": [
        "### Checking Our Thread\n",
        "\n",
        "Now we can get a list of messages from our thread!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Av-OQDUPvhAd"
      },
      "outputs": [],
      "source": [
        "messages = client.beta.threads.messages.list(\n",
        "  thread_id=thread.id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM6cZk-GviqX",
        "outputId": "03f1a135-ce62-42e4-9e5e-203c91ffaf83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Message(id='msg_1MW5RPPaUer8JzmZyMSGq4od', assistant_id='asst_eGgBBayHusd016cplTLvOJlr', completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Pediatric dentists specialize in the dental development and specific needs of children, receiving two to three years of additional training focused on treating young patients. They are also equipped to provide a comfortable, child-friendly environment that eases the anxiety associated with dental visits.'), type='text')], created_at=1712928537, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_Nq5fLRcpo49bkXzEgR7m6a9M', status=None, thread_id='thread_w2UnIiuXcXI4IoWCAxQxzeLT')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages.data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgnY16tjCmc6"
      },
      "source": [
        "## Adding Tools\n",
        "\n",
        "Now that we have an understanding of how Assistant works, we can start thinking about adding tools.\n",
        "\n",
        "We'll go through 3 separate tools and explore how we can leverage them!\n",
        "\n",
        "Let's start with the most familiar tool - the Retriever!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0NagnlZC8g9"
      },
      "source": [
        "### Creating an Assistant with the Retriever Tool\n",
        "\n",
        "The first thing we'll want to do is create an assistant with the Retriever tool.\n",
        "\n",
        "This is also going to require some data. We'll provided data - but you're very much encouraged to use your own files to explore how the Assistant works for your use case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HInYwNiQEjQH"
      },
      "source": [
        "#### Collect and Add Data\n",
        "\n",
        "First, we need some data. Second, we need to add the data to our Assistant!\n",
        "\n",
        "Let's start with grabbing some data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvAHBszIEa1Y"
      },
      "outputs": [],
      "source": [
        "!wget https://www.gutenberg.org/files/84/84-h/84-h.htm -o frankenstein.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find and download my corpus from local\n",
        "Jay: I manually added my corpus. My content is stored in Webflow CMS - a web design app. Ideally I would make a call to the CMS to download my content but I did not not want to work on that piece to stay in scope for this exercise. faq.txt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/System/Volumes/Data/Users/acrobat/Desktop/Voiceflow/knowledge base/V3/faqv3.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def find_file(filename, search_path):\n",
        "    for root, dir, files in os.walk(search_path):\n",
        "        if filename in files:\n",
        "            return os.path.join(root, filename)\n",
        "\n",
        "# Replace 'myfile.txt' with your file name and '/' with your search path\n",
        "file_path = find_file('faqv3.txt', '/')\n",
        "print(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cp \"/System/Volumes/Data/Users/acrobat/Desktop/Voiceflow/knowledge base/V3/faqv3.txt\" faqv3.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2EpY1w_FQ3m"
      },
      "source": [
        "Now we can upload our file!\n",
        "\n",
        "Pay attention to [this](https://platform.openai.com/docs/assistants/tools/supported-files) documentation to see what kinds of files can be uploaded.\n",
        "\n",
        "> NOTE: Per the OpenAI [docs](https://platform.openai.com/docs/assistants/tools/knowledge-retrieval) The maximum file size is 512 MB and no more than 2,000,000 tokens (computed automatically when you attach a file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "dpVoe2SMFI6s"
      },
      "outputs": [],
      "source": [
        "file_reference = client.files.create(\n",
        "  file=open(\"faqv3.txt\", \"rb\"),\n",
        "  purpose='assistants'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBQOSGyyF2u5"
      },
      "source": [
        "Let's look at what our `file_reference` contains!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJrVLkMpFgwf",
        "outputId": "b8e8d01a-faf8-4308-cc49-54c11415e245"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FileObject(id='file-OeOr9biNmtGwwkjbkcp8xlq1', bytes=11043, created_at=1712932251, filename='faqv3.txt', object='file', purpose='assistants', status='processed', status_details=None)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd4O4dpZF-eH"
      },
      "source": [
        "#### Create and Use Assistant\n",
        "\n",
        "Now that we have our file - we can attach it to an Assistant, and we can give that Assistant the ability to use it for retrieval through the Retrieval tool!\n",
        "\n",
        "> NOTE: Please pay attention to [pricing](https://platform.openai.com/docs/assistants/tools/knowledge-retrieval) and don't forget to delete your files when you're done!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Here we are also updating the name appending + Retrieval to the name of the assistant. mine is Poppy + Retrieval. Here also assigning the rerieval tool using tools..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jfn_MlJqFiEe"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  name=name + \"+ Retrieval\",\n",
        "  instructions=instructions,\n",
        "  model=model,\n",
        "  tools=[{\"type\": \"retrieval\"}],\n",
        "  file_ids=[file_reference.id]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0-mmRjQGeUR"
      },
      "source": [
        "Let's try submitting a message to our Assistant and seeing what kind of answer we get!\n",
        "\n",
        "We'll outline the steps needed to do this in full:\n",
        "\n",
        "1. Create an Assistant\n",
        "2. Create a Thread\n",
        "3. Add Messages to that Thread\n",
        "4. Create a Run on that Thread\n",
        "5. Wait for Run to Complete\n",
        "6. Collect Messages from the Thread\n",
        "\n",
        "Let's do that below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOKtb9PsGiB1",
        "outputId": "043ecfc0-2277-4b39-ba6b-fdf8a741e70f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "queued\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n"
          ]
        }
      ],
      "source": [
        "# Create a Thread\n",
        "thread = client.beta.threads.create()\n",
        "\n",
        "# Add Messages to that Thread\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=f\"What to do if my child's tooth is wiggly?\"\n",
        ")\n",
        "\n",
        "# Create a Run on that Thread\n",
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        ")\n",
        "\n",
        "# Wait for Run to Complete\n",
        "while run.status == \"in_progress\" or run.status == \"queued\":\n",
        "  time.sleep(1)\n",
        "  print(run.status)\n",
        "  run = client.beta.threads.runs.retrieve(\n",
        "    thread_id=thread.id,\n",
        "    run_id=run.id\n",
        "  )\n",
        "\n",
        "# Collect Messages from the Thread\n",
        "messages = client.beta.threads.messages.list(\n",
        "  thread_id=thread.id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxJfa-saHbNQ"
      },
      "source": [
        "Let's look at the final result!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19nDqjRgHaNA",
        "outputId": "f4ad3574-2056-4253-d406-f7057ef73dae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[Message](data=[Message(id='msg_LXerNK4rSONzpOr19rLaAEEz', assistant_id='asst_sK66WSETvfQiRP7RlXzYMCWB', completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=312, file_citation=FileCitation(file_id='file-OeOr9biNmtGwwkjbkcp8xlq1', quote=''), start_index=302, text='„Äê5‚Ä†source„Äë', type='file_citation')], value=\"If your child has a wiggly tooth, encourage them to gently wiggle it but avoid forcing it out before it's ready, as this can cause pain and increase the risk of infection. If the loose tooth is causing discomfort or there are concerns about its progression, consider consulting with a pediatric dentist„Äê5‚Ä†source„Äë.\"), type='text')], created_at=1712943837, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_KWmqy4QJbXAeWL6mD2uuDPRL', status=None, thread_id='thread_XD2WT6Gpkha7tXKr30CW61I3'), Message(id='msg_26ppltFlv94xJHYfSGP6AKJm', assistant_id=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"What to do if my child's tooth is wiggly?\"), type='text')], created_at=1712943833, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_XD2WT6Gpkha7tXKr30CW61I3')], object='list', first_id='msg_LXerNK4rSONzpOr19rLaAEEz', last_id='msg_26ppltFlv94xJHYfSGP6AKJm', has_more=False)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JdzJDvmHyNF"
      },
      "source": [
        "Let's do some clean up to make sure we're not being charged anything extra by deleting our resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "01EYWyWBHaoC"
      },
      "outputs": [],
      "source": [
        "file_deletion_status = client.beta.assistants.files.delete(\n",
        "  assistant_id=assistant.id,\n",
        "  file_id=file_reference.id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pln9uYoJICno"
      },
      "source": [
        "### Creating an Assistant with the Code Interpreter Tool\n",
        "\n",
        "Now that we've explored the Retrieval Tool - let's try the Code Interpreter tool!\n",
        "\n",
        "The process will be almost exactly the same - but we can explore a different query, and we'll add our file at the Message level!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "IC81y_VtH9lw"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  name=name + \"+ Code Interpreter\",\n",
        "  instructions=instructions,\n",
        "  model=model,\n",
        "  tools=[{\"type\": \"code_interpreter\"}],\n",
        "  #file_ids=[file_reference.id]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJPHAJCQJbgi"
      },
      "source": [
        "In the following example, we'll also see how we can package the Thread creation with the Message adding step!\n",
        "\n",
        "> NOTE: Files added at the message/thread level will not be available to the Assistant outside of that Thread."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "5xVdjH6EJQrr"
      },
      "outputs": [],
      "source": [
        "thread = client.beta.threads.create(\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"What kind of file is this?\",\n",
        "      \"file_ids\": [file_reference.id]\n",
        "    }\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiIYut_dJ0Cv"
      },
      "source": [
        "> NOTE: Remember that we create runs at the *thread* level - and so don't need the message object to continue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES8laUe_Jwp_",
        "outputId": "7a9b004f-d824-4cca-f21f-bbbd9a55c4c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "queued\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n"
          ]
        }
      ],
      "source": [
        "# Create a Run on that Thread\n",
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        ")\n",
        "\n",
        "# Wait for Run to Complete\n",
        "while run.status == \"in_progress\" or run.status == \"queued\":\n",
        "  time.sleep(1)\n",
        "  print(run.status)\n",
        "  run = client.beta.threads.runs.retrieve(\n",
        "    thread_id=thread.id,\n",
        "    run_id=run.id\n",
        "  )\n",
        "\n",
        "# Collect Messages from the Thread\n",
        "messages = client.beta.threads.messages.list(\n",
        "  thread_id=thread.id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYPpGJz5KoDf"
      },
      "source": [
        "We can check the specific steps that the Code Interpreter ran to figure out what steps the Assistant took!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "or7iJ492KI2P"
      },
      "outputs": [],
      "source": [
        "run_steps = client.beta.threads.runs.steps.list(\n",
        "  thread_id=thread.id,\n",
        "  run_id=run.id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwbzExbmKJ4N",
        "outputId": "da00f537-adda-46ac-9a98-79478751e28f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_wq3MyjFuTsqqHqeJsyxxxOZu'), type='message_creation')\n",
            "ToolCallsStepDetails(tool_calls=[CodeInterpreterToolCall(id='call_B9Vecod4LcRnbJ0eKlxznDdO', code_interpreter=CodeInterpreter(input=\"import mimetypes\\r\\n\\r\\n# Identify the MIME type of the uploaded file\\r\\nfile_path = '/mnt/data/file-dTXnmJy2IJCxjBiQHNAblQuE'\\r\\nmime_type, _ = mimetypes.guess_type(file_path)\\r\\nmime_type\", outputs=[CodeInterpreterOutputLogs(logs='', type='logs')]), type='code_interpreter')], type='tool_calls')\n"
          ]
        }
      ],
      "source": [
        "for step in run_steps.data:\n",
        "  print(step.step_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNJeFF6JJ62H",
        "outputId": "d7565eca-5f49-429d-9d4a-220e22d746c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[Message](data=[Message(id='msg_wq3MyjFuTsqqHqeJsyxxxOZu', assistant_id='asst_fGDdS7H1qAMpgz2RpYOjVTde', completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='The MIME type of the uploaded file could not be determined. It might be necessary to inspect the content or extension of the file for additional clues.'), type='text')], created_at=1712948774, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_qnJHDTgiXW6xi0uRjKa1D6g6', status=None, thread_id='thread_cLpgd9xGAF2xVLmYRfWtzwb8'), Message(id='msg_XgL79pmNQLVspyJX5Pzspy3B', assistant_id=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='What kind of file is this?'), type='text')], created_at=1712948762, file_ids=['file-dTXnmJy2IJCxjBiQHNAblQuE'], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_cLpgd9xGAF2xVLmYRfWtzwb8')], object='list', first_id='msg_wq3MyjFuTsqqHqeJsyxxxOZu', last_id='msg_XgL79pmNQLVspyJX5Pzspy3B', has_more=False)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "JdLC0rsvR5m5"
      },
      "outputs": [],
      "source": [
        "file_deletion_status = client.beta.assistants.files.delete(\n",
        "  assistant_id=assistant.id,\n",
        "  file_id=file_reference.id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi10hON2LQmc"
      },
      "source": [
        "And there you go!\n",
        "\n",
        "We've fit our Assistant with an awesome Code Interpreter that lets our Assistant run code on our provided files!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdJxt77oLzu7"
      },
      "source": [
        "### Creating an Assistant with a Function Calling Tool\n",
        "\n",
        "Let's finally create an Assistant that utilizes the Function Calling API.\n",
        "\n",
        "We'll start by creating a function that we wish to be called.\n",
        "\n",
        "We'll utilize DuckDuckGo search to allow our Assistant to have the most up to date information!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5eKEC2wMMVI",
        "outputId": "8077815f-153d-4e9f-c315-74c12035bde7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU duckduckgo_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "YPFZ_Uq_LawH"
      },
      "outputs": [],
      "source": [
        "from duckduckgo_search import DDGS\n",
        "\n",
        "def duckduckgo_search(query):\n",
        "  with DDGS() as ddgs:\n",
        "    results = [r for r in ddgs.text(query, max_results=5)]\n",
        "    return \"\\n\".join(result[\"body\"] for result in results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-o1TBFpMSvR"
      },
      "source": [
        "Let's test our function to make sure it behaves as we expect it to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "mCUr9jFCMWBw",
        "outputId": "368ab562-a1f1-4660-d07b-4e597cdc9fac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A study by Harvard Business School found that a 1-star increase in Yelp ratings leads to a 5-9% increase in revenue. And while a Google review may not have as much of an impact, they can still lead to more sales and revenue for your business. So, if you want to improve your local SEO, build trust and credibility, and generate more sales, ensure ...\\nHow to use the calculator correctly. The 5-star rating calculator is a handy little tool that can help you figure out how many more reviews you need to get your overall or average rating to 5 stars. Here are a few examples of how to use it correctly: 1. Enter the current number of reviews you have. 2. Enter the current average rating you have. 3.\\nSimilar to other types of reviews, recipe cards in search results show the average review rating and the total number of reviews. Screenshot from search for [best vegan winter recipes], Google ...\\nA 5-star rating can be what you need to stand out in search results. Trust and SEO: Positive Google reviews boost trust and improve local search rankings. Quantity vs. Quality: Google removed the minimum review requirement for star ratings. Ratings depend on the number and quality of reviews. Avoid Buying Reviews: Buying reviews is against ...\\nThe Google star rating system is based on a scale of 1 to 5 stars, with 1 being the lowest and 5 being the highest. The rating is determined by a complex algorithm that considers several factors such as the number of reviews, the overall sentiment of the reviews, and the relevance of the reviews to the business.'"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "duckduckgo_search(\"How many 5 star Google reviews does a pediatric dentistry need to place at top of Google search results?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzE1nxt5Mi80"
      },
      "source": [
        "Now we need to express how our function works in a way that is compatible with the OpenAI Function Calling API.\n",
        "\n",
        "We'll want to provide a `JSON` object that includes what parameters we have, how to call them, and a short natural language description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "8ElrWvBnMY_s"
      },
      "outputs": [],
      "source": [
        "ddg_function = {\n",
        "    \"name\" : \"duckduckgo_search\",\n",
        "    \"description\" : \"Answer non-technical questions. \",\n",
        "    \"parameters\" : {\n",
        "        \"type\" : \"object\",\n",
        "        \"properties\" : {\n",
        "            \"query\" : {\n",
        "                \"type:\" : \"string\",\n",
        "                \"description\" : \"The search query to use. For example: 'What is the importance of Google reviews in local SEO?'\"\n",
        "            }\n",
        "        },\n",
        "        \"required\" : [\"query\"]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyRmJgEQVuGs"
      },
      "source": [
        "####‚ùì Question\n",
        "\n",
        "Why does the description key-value pair matter?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ANSWER:\n",
        "It helps clarify the purpose and usage of the function. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tir4WySGM0x2"
      },
      "source": [
        "Now when we create our Assistant - we'll want to include the function description as a tool using the following format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jay: Can I assign multiple functions simultanously?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "4eFpwi12Mzlg"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=name + \" + Function Calling API\",\n",
        "    instructions=instructions,\n",
        "    tools=[\n",
        "        {\"type\": \"function\",\n",
        "         \"function\" : ddg_function\n",
        "        }\n",
        "    ],\n",
        "    model=model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJCLvWZzNIXR"
      },
      "source": [
        "We need to make a few modifications to our Assistant to include the ability to make calls to our local function and pass the results back to our Assistant for further generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "XHRfvGJ_NQnF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def wait_for_run_completion(thread_id, run_id):\n",
        "    \"\"\"\n",
        "    Waits for the completion of a run identified by the given thread ID and run ID.\n",
        "\n",
        "    Args:\n",
        "        thread_id (str): The ID of the thread containing the run.\n",
        "        run_id (str): The ID of the run to wait for.\n",
        "\n",
        "    Returns:\n",
        "        dict: The details of the completed run.\n",
        "\n",
        "    Raises:\n",
        "        None\n",
        "\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n",
        "        print(f\"Current run status: {run.status}\")\n",
        "        if run.status in ['completed', 'failed', 'requires_action']:\n",
        "            return run\n",
        "\n",
        "def submit_tool_outputs(thread_id, run_id, tools_to_call):\n",
        "    \"\"\"\n",
        "    Submits the tool outputs to the specified thread and run.\n",
        "\n",
        "    Args:\n",
        "        thread_id (str): The ID of the thread to submit the tool outputs to.\n",
        "        run_id (str): The ID of the run to submit the tool outputs to.\n",
        "        tools_to_call (list): A list of tools to call and retrieve outputs from.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the submitted tool outputs.\n",
        "\n",
        "    \"\"\"\n",
        "    tool_output_array = []\n",
        "    for tool in tools_to_call:\n",
        "        output = None\n",
        "        tool_call_id = tool.id\n",
        "        function_name = tool.function.name\n",
        "        function_args = tool.function.arguments\n",
        "\n",
        "        if function_name == \"duckduckgo_search\":\n",
        "            print(\"Consulting Duck Duck Go...\")\n",
        "            output = duckduckgo_search(query=json.loads(function_args)[\"query\"])\n",
        "\n",
        "        if output:\n",
        "            tool_output_array.append({\"tool_call_id\": tool_call_id, \"output\": output})\n",
        "\n",
        "    print(tool_output_array)\n",
        "\n",
        "    return client.beta.threads.runs.submit_tool_outputs(\n",
        "        thread_id=thread_id,\n",
        "        run_id=run_id,\n",
        "        tool_outputs=tool_output_array\n",
        "    )\n",
        "\n",
        "def print_messages_from_thread(thread_id):\n",
        "    \"\"\"\n",
        "    Prints the messages from a given thread.\n",
        "\n",
        "    Args:\n",
        "        thread_id (str): The ID of the thread.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
        "    for msg in messages:\n",
        "        print(f\"{msg.role}: {msg.content[0].text.value}\")\n",
        "\n",
        "def use_assistant(query, assistant_id, thread_id=None):\n",
        "    \"\"\"\n",
        "    Uses the OpenAI Assistant to interact with the AI model.\n",
        "\n",
        "    Args:\n",
        "        query (str): The user's query or message.\n",
        "        assistant_id (str): The ID of the OpenAI Assistant.\n",
        "        thread_id (str, optional): The ID of the thread to use. If not provided, a new thread will be created.\n",
        "\n",
        "    Returns:\n",
        "        str: The ID of the thread used for the conversation.\n",
        "    \"\"\"\n",
        "    thread = client.beta.threads.create()\n",
        "\n",
        "    message = client.beta.threads.messages.create(\n",
        "        thread_id=thread.id,\n",
        "        role=\"user\",\n",
        "        content=query,\n",
        "    )\n",
        "\n",
        "    print(\"Creating Assistant \")\n",
        "\n",
        "    run = client.beta.threads.runs.create(\n",
        "        thread_id=thread.id,\n",
        "        assistant_id=assistant_id,\n",
        "    )\n",
        "\n",
        "    print(\"Querying OpenAI Assistant Thread.\")\n",
        "\n",
        "    run = wait_for_run_completion(thread.id, run.id)\n",
        "\n",
        "    if run.status == 'requires_action':\n",
        "        run = submit_tool_outputs(thread.id, run.id, run.required_action.submit_tool_outputs.tool_calls)\n",
        "        run = wait_for_run_completion(thread.id, run.id)\n",
        "\n",
        "    print_messages_from_thread(thread.id)\n",
        "\n",
        "    return thread.id\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoChJ771Uo0B"
      },
      "source": [
        "####‚ùì Question\n",
        "\n",
        "Outline, in simple terms, what the `use_assistant` helper function is doing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ANSWER\n",
        "The use_assistant function is the main function that uses the assistant. It creates a new thread, creates a new message in the thread with the user's query, and creates a new run with the assistant. If the run requires action, it submits the tool outputs and waits for the run to complete. Finally, it prints all the messages from the thread and returns the thread id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5NR_HYINky8",
        "outputId": "60042cd6-117f-423e-9f75-5ea1d663c602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: requires_action\n",
            "Consulting Duck Duck Go...\n",
            "[{'tool_call_id': 'call_nDMnWA1z7x8MZvoihT5zGnVs', 'output': \"1) The Owner Sets The Review Stage. 65% of review writers have left negative reviews after experiencing bad or rude customer service, and an additional 28% say their negative reviews result from businesses failing to resolve their complaints at the time of service. One of the best paths to building a sterling local business reputation is to run ...\\nPlus, skillful review management can also impact a business's success. Hence, you may have already got a gist of why are Google Reviews important. Now, let's dive into the 7 staggering benefits of Google Reviews in detail! 1. Increases Trust and Credibility. Google dominates the search engine market with a 92% share.\\nHow Reviews & Ratings Impact Local SEO for Google Maps. For listings on Google Maps, our local rank trackers found that the average number of reviews for a listing had a significantly stronger impact on its performance, compared to average rating. In fact, we found that average rating did not correlate with placement for the first three positions.\\nGetting Google reviews for your business will also impact your website's SEO considerably. Below mentioned here are a few ways in which you can improve the SEO of your website through Google reviews: 1. Local SEO can be improved. Positive Google reviews can boost your local search engine rankings.\\nTo get to your reviews in Google search, simply search for your business name or enter the words [My Business] in the search bar. You will see your Business Profile manager panel on the left-hand ...\"}]\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: Yes, Google reviews are vital for local SEO as they can significantly impact your business's visibility and search engine rankings on Google Maps and local searches. Positive reviews increase trust and credibility, which can boost your search position.\n",
            "user: Do I need Goggle reviews for local SEO?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'thread_esMzUcQOK8dh25E6HvpTdxzV'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "use_assistant(\"Do I need Goggle reviews for local SEO?\", assistant.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY51QtkGNvQe"
      },
      "source": [
        "## Wrapping it All Together (Super good)\n",
        "\n",
        "Now we can create an Assistant with all of the available tools and see how it responds to various queries!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "HaoQSB7CN74T"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=name + \" + All Tools\",\n",
        "    instructions=instructions,\n",
        "    tools=[\n",
        "        {\"type\": \"code_interpreter\"},\n",
        "        {\"type\": \"retrieval\"},\n",
        "        {\"type\": \"function\", \"function\" : ddg_function}\n",
        "    ],\n",
        "    model=model,\n",
        "    file_ids=[file_reference.id],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2GtwoGDPwp2",
        "outputId": "e276723d-54e1-41ff-8b47-ef725caaabb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: Choosing a pediatric dentist over a general dentist is recommended because pediatric dentists receive specialized training in caring for children‚Äôs teeth, gums, and mouth through all stages of childhood. They are also trained to handle the unique behavioral needs of children, making dental visits more positive and effective for young patients.\n",
            "user: Why should I choose a pediatric dentist over a general dentist?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'thread_eEcsOtjN1MJb6xMlj07cpvLe'"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "use_assistant(\"Why should I choose a pediatric dentist over a general dentist?\", assistant.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QjcxpQ5P-HX",
        "outputId": "43f6a9be-ad9b-4177-92bb-6064dbc0d88b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: The document contains a total of 11 questions.\n",
            "user: How many questions are there in my document?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'thread_W1oO6LbADHBSQ02WNMF1j8fI'"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "use_assistant(\"How many questions are there in my document?\", assistant.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSKL96nvQIUq",
        "outputId": "e054c800-7c54-4601-d972-4b3c5dc1125d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: - When is a good time for a child's first dental visit and what should parents expect?\n",
            "- What age should children start getting dental x-rays and why are they important?\n",
            "- What's the best age to introduce an electric toothbrush to children and which type is recommended?\n",
            "- Why do children's teeth sometimes appear yellow and how can it be addressed?\n",
            "- How can parents determine the right time for their child to visit an orthodontist?\n",
            "- What age do children typically lose their first tooth and what should parents do when their child's tooth is wiggly?\n",
            "- Until what age does your pediatric dental practice provide care for patients?\n",
            "- What is the ideal age for children to stop using a pacifier or engaging in thumb sucking?\n",
            "- When is it appropriate to evaluate a child for wisdom tooth extraction?\n",
            "- What age is it safe for teenagers to begin teeth whitening procedures?\n",
            "- What age should children start brushing and flossing their teeth independently?\n",
            "- Why should your child see a Board-Certified Pediatric Dentist?\n",
            "- Can I stay with my child during the treatment?\n",
            "user: Extract all questions in my document as  bullet points. I only want the questions.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'thread_OrnTmB0SnJ042iKZPisRsWaH'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "use_assistant(\"Extract all questions in my document as  bullet points. I only want the questions.\", assistant.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm0oYJu7VAjg"
      },
      "source": [
        "####‚ùì Question\n",
        "\n",
        "Notice that our response can go through multiple paths, given that:\n",
        "\n",
        "What is \"deciding\" to use the tool?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ANSWER:\n",
        "I think the answer is both sequential and contextual logic. This makes the most sense to me. I think this is the reason we add answer non technical question. The model checks the knowledge base first (retrival). If it does not find the answer there then moves on to the web search. This is controlled by the \"non technical\" question part. if there is any math / coding involved it defaults to the code retrieval tool.\n",
        "One interesting thing would be to try to add the coding questions answer to the knowledge base. In my example I have 13 questions with answers in my document. What if one of my question asked: How many questions are there in my document? And the answer was 20 instead of the correct 13. Would it return 20 since it finds the answer in my knowledge base?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrJWQ4XvZ20K"
      },
      "source": [
        "### Adding JSON Mode for More Agentic Behaviour\n",
        "\n",
        "Finally, we have the ability to select tools - all we need to do now is set up a process to allow us to create some kind of loop and make decisions about whether or not the response is complete or not.\n",
        "\n",
        "We'll leverage the OpenAI completions end-endpoint with JSON mode to let us understand when we've adequately answered our user's question!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Rzrk8gn2anpe"
      },
      "outputs": [],
      "source": [
        "completed_template = \\\n",
        "\"\"\"\n",
        "Does this response adequately answer the user's query?\n",
        "\n",
        "Please return your response in JSON format - with key: \"completed\" and either True (if completed) or False (if not completed)\n",
        "\n",
        "User Query:\n",
        "{query}\n",
        "\n",
        "Assistant Response:\n",
        "{response}\n",
        "\"\"\"\n",
        "\n",
        "def is_complete(query, response):\n",
        "  completed_response = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": completed_template.format(query=query, response=response),\n",
        "          }\n",
        "      ],\n",
        "      model=model,\n",
        "      response_format={\"type\" : \"json_object\"}\n",
        "  )\n",
        "\n",
        "  return completed_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kCQrx03brge",
        "outputId": "2e2a716d-718f-4e06-bf80-a58922180441"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: The provided file is 11,043 bytes in size.\n",
            "user: How many bytes is the provided file?\n"
          ]
        }
      ],
      "source": [
        "query = \"How many bytes is the provided file?\"\n",
        "\n",
        "thread_id_for_response = use_assistant(query, assistant.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSJs9oDIgBTK"
      },
      "source": [
        "Now we can observe JSON mode in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "MSDsmlDBcYk_"
      },
      "outputs": [],
      "source": [
        "messages = client.beta.threads.messages.list(thread_id=thread_id_for_response)\n",
        "response = messages.data[0].content[0].text.value\n",
        "completed_flag = json.loads(is_complete(query, response).choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[Message](data=[Message(id='msg_t1QJ4ozNngEAkA7YxWcFdddj', assistant_id='asst_dYx26lafARyFiozBz5MfFNZg', completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='The provided file is 11,043 bytes in size.'), type='text')], created_at=1712951728, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_O60vqxyOrMBAkfUWrR0SPbjD', status=None, thread_id='thread_uDRImtznWXjo2SjeKSuwSCuP'), Message(id='msg_YgKDf549KUJb9AjbDGLSfL9X', assistant_id=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='How many bytes is the provided file?'), type='text')], created_at=1712951723, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_uDRImtznWXjo2SjeKSuwSCuP')], object='list', first_id='msg_t1QJ4ozNngEAkA7YxWcFdddj', last_id='msg_YgKDf549KUJb9AjbDGLSfL9X', has_more=False)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The provided file is 11,043 bytes in size.'"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-SKB6TWf_Ra",
        "outputId": "e2fdb56c-ca8a-4011-ff25-eb55d8dc5d1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'completed': True}\n"
          ]
        }
      ],
      "source": [
        "completed_flag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bivIAVh0dTwA"
      },
      "source": [
        "## üöß BONUS CHALLENGE üöß:\n",
        "\n",
        "Use the components we've constructed so far to build a loop that lets us continue to query the Assistant if the response is not completed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "vtWh_h_WfjuS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: I don't have access to information about what's currently in your pocket. If you have a different question, particularly about pediatric dentistry or something related to a document you've uploaded, I'd be happy to help with that!\n",
            "user: What is in my pocket right now?\n",
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: I don't have the ability to know or detect what is physically in your pocket. If this is related to the content of a document or file you've uploaded, please specify or ask a related question to that content.\n",
            "user: What is in my pocket right now?\n"
          ]
        }
      ],
      "source": [
        "### YOUR CODE HERE: not sure how to test this other then this. Sometimes it runs for 5 cycles, sometimes just twice. \n",
        "\n",
        "\n",
        "query = \"What is in my pocket right now?\"\n",
        "completed_flag = False\n",
        "\n",
        "while completed_flag == False:\n",
        "    thread_id_for_response = use_assistant(query, assistant.id)\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread_id_for_response)\n",
        "    response = messages.data[0].content[0].text.value\n",
        "    completed_flag = json.loads(is_complete(query, response).choices[0].message.content)['completed']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "completed_flag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJjYm6gnfWrS"
      },
      "source": [
        "# Make Sure You Delete Resources\n",
        "\n",
        "Make sure you delete all the resources you created!\n",
        "\n",
        "This function will help you do so!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62b49AleR6m_"
      },
      "outputs": [],
      "source": [
        "file_deletion_status = client.beta.assistants.files.delete(\n",
        "  assistant_id=assistant.id,\n",
        "  file_id=file_reference.id\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
